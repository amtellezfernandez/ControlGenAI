{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance import user, assistant, select, system, gen\n",
    "from guidance import models\n",
    "from guidance import gen, select\n",
    "import transformers\n",
    "from guidance.models import Transformers\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import glob\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0d2354853749a48eea782a9269cb34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "# Load tokenizer and model\n",
    "tokenizer_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "# tokenizer_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "# tokenizer_name = \"modelscope/Yi-1.5-34B-Chat-AWQ\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(tokenizer_name, device_map=\"cuda\", trust_remote_code=True, torch_dtype=\"auto\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frame",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
